{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>Bonus</th>\n",
       "      <th>1_prize</th>\n",
       "      <th>2_prize</th>\n",
       "      <th>3_prize</th>\n",
       "      <th>4_prize</th>\n",
       "      <th>5_prize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>968</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>24</td>\n",
       "      <td>39</td>\n",
       "      <td>33</td>\n",
       "      <td>1667729683</td>\n",
       "      <td>37251694</td>\n",
       "      <td>1159633</td>\n",
       "      <td>50000</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>967</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "      <td>40</td>\n",
       "      <td>9</td>\n",
       "      <td>5809776094</td>\n",
       "      <td>56133103</td>\n",
       "      <td>1564923</td>\n",
       "      <td>50000</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>966</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>25</td>\n",
       "      <td>29</td>\n",
       "      <td>34</td>\n",
       "      <td>37</td>\n",
       "      <td>36</td>\n",
       "      <td>2411303513</td>\n",
       "      <td>80376784</td>\n",
       "      <td>1708691</td>\n",
       "      <td>50000</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>965</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>25</td>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "      <td>36</td>\n",
       "      <td>34</td>\n",
       "      <td>3403348929</td>\n",
       "      <td>86316821</td>\n",
       "      <td>1662024</td>\n",
       "      <td>50000</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>964</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>36</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>43</td>\n",
       "      <td>30</td>\n",
       "      <td>2345861063</td>\n",
       "      <td>75187855</td>\n",
       "      <td>1597781</td>\n",
       "      <td>50000</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time  1   2   3   4   5   6  Bonus     1_prize   2_prize  3_prize  4_prize  \\\n",
       "0   968  2   5  12  14  24  39     33  1667729683  37251694  1159633    50000   \n",
       "1   967  1   6  13  37  38  40      9  5809776094  56133103  1564923    50000   \n",
       "2   966  1  21  25  29  34  37     36  2411303513  80376784  1708691    50000   \n",
       "3   965  2  13  25  28  29  36     34  3403348929  86316821  1662024    50000   \n",
       "4   964  6  21  36  38  39  43     30  2345861063  75187855  1597781    50000   \n",
       "\n",
       "   5_prize  \n",
       "0     5000  \n",
       "1     5000  \n",
       "2     5000  \n",
       "3     5000  \n",
       "4     5000  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colnames = ['Time', '1','2','3','4','5','6','Bonus','1_prize','2_prize','3_prize','4_prize','5_prize']\n",
    "data = pd.read_csv('lotto_data.csv',names=colnames)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 7) (100, 7) (68, 7)\n"
     ]
    }
   ],
   "source": [
    "train_data = data.iloc[0:800, 1:8]\n",
    "valid_data = data.iloc[800:900, 1:8]\n",
    "test_data = data.iloc[900:,1:8]\n",
    "print(train_data.shape, valid_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_train_data = {'data':[], 'label':[]}\n",
    "for i in range(800-6):\n",
    "    temp = []\n",
    "    for j in range(i,i+5):\n",
    "        temp.append(train_data.iloc[j])\n",
    "    label = [0 for i in range(45)]\n",
    "    for n in train_data.iloc[i+5]:\n",
    "        label[n-1] = 1\n",
    "    \n",
    "    pre_train_data['data'].append(temp)\n",
    "    pre_train_data['label'].append(label)\n",
    "    \n",
    "pre_valid_data = {'data':[], 'label':[]}\n",
    "for i in range(100-6):\n",
    "    temp = []\n",
    "    for j in range(i,i+5):\n",
    "        temp.append(valid_data.iloc[j])\n",
    "    label = [0 for i in range(45)]\n",
    "    for n in valid_data.iloc[i+5]:\n",
    "        label[n-1] = 1\n",
    "    \n",
    "    pre_valid_data['data'].append(temp)\n",
    "    pre_valid_data['label'].append(label)\n",
    "    \n",
    "pre_test_data = {'data':[], 'label':[]}\n",
    "for i in range(68-6):\n",
    "    temp = []\n",
    "    for j in range(i,i+5):\n",
    "        temp.append(test_data.iloc[j])\n",
    "    label = [0 for i in range(45)]\n",
    "    for n in valid_data.iloc[i+5]:\n",
    "        label[n-1] = 1\n",
    "    \n",
    "    pre_test_data['data'].append(temp)\n",
    "    pre_test_data['label'].append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(794, 2) (94, 2) (62, 2)\n"
     ]
    }
   ],
   "source": [
    "pre_test_data = pd.DataFrame(pre_test_data)\n",
    "pre_valid_data = pd.DataFrame(pre_valid_data)\n",
    "pre_train_data = pd.DataFrame(pre_train_data)\n",
    "print(pre_train_data.shape, pre_valid_data.shape, pre_test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_train_data.to_csv('./pre_train_data.csv', index=False)\n",
    "pre_valid_data.to_csv('./pre_valid_data.csv', index=False)\n",
    "pre_test_data.to_csv('./pre_test_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Predictor, self).__init__()\n",
    "        \n",
    "        self.Conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 1, out_channels = 4, kernel_size = 2),\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.LeakyReLU(0.3),\n",
    "            nn.Conv2d(in_channels = 4, out_channels = 8, kernel_size = 2),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.LeakyReLU(0.3),\n",
    "            nn.Conv2d(in_channels = 8, out_channels = 16, kernel_size = 2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.LeakyReLU(0.3)\n",
    "        ) \n",
    "        self.flatten = nn.Sequential(\n",
    "            nn.Linear(128, 45),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.Conv(x)\n",
    "        out = torch.reshape(out,(-1,128))\n",
    "        out = self.flatten(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Predictor().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr = 0.02)\n",
    "loss_func = nn.BCEWithLogitsLoss()\n",
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 0  train_loss:  0.6940491893880013  val_loss:  0.6931489946994376\n",
      "ep: 5  train_loss:  0.693147199580291  val_loss:  0.6931473771308331\n",
      "ep: 10  train_loss:  0.6931471829900814  val_loss:  0.6931472325578649\n",
      "ep: 15  train_loss:  0.6931471824645996  val_loss:  0.6931471970487149\n",
      "ep: 20  train_loss:  0.6931471824645996  val_loss:  0.6931471856350594\n",
      "ep: 25  train_loss:  0.6931471824645996  val_loss:  0.6931471843668755\n",
      "ep: 30  train_loss:  0.6931471824645996  val_loss:  0.6931471837327835\n",
      "ep: 35  train_loss:  0.6931471824645996  val_loss:  0.6931471837327835\n",
      "ep: 40  train_loss:  0.6931471824645996  val_loss:  0.6931471824645996\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-173-3342667199dc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mlosses\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m             \u001b[0mbeta1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'betas'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m             F.adam(params_with_grad,\n\u001b[0m\u001b[0;32m    109\u001b[0m                    \u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m                    \u001b[0mexp_avgs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\optim\\functional.py\u001b[0m in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[1;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m         \u001b[0mexp_avg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m         \u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for e in range(epochs):\n",
    "    losses = 0\n",
    "    \n",
    "    for data in np.array(pre_train_data):\n",
    "        x = np.expand_dims(np.expand_dims(np.array(data[0])/45, axis=0), axis=0)\n",
    "        x = torch.tensor(x, dtype=torch.float).to(device)\n",
    "        y = np.expand_dims(data[1], axis=0)\n",
    "        y = torch.tensor(y, dtype=torch.float).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model.forward(x)\n",
    "        loss = loss_func(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses += loss.cpu().data.numpy()\n",
    "    \n",
    "    val_losses = 0\n",
    "    with torch.no_grad():\n",
    "        for data in np.array(pre_valid_data):\n",
    "            x = np.expand_dims(np.expand_dims(np.array(data[0])/45, axis=0), axis=0)\n",
    "            x = torch.tensor(x, dtype=torch.float).to(device)\n",
    "            y = np.expand_dims(data[1], axis=0)\n",
    "            y = torch.tensor(y, dtype=torch.float).to(device)\n",
    "\n",
    "            output = model.forward(x)\n",
    "            loss = loss_func(output, y)\n",
    "            val_losses += loss.cpu().data.numpy()\n",
    "        \n",
    "    if e % 5 == 0:\n",
    "        print(\"ep:\", e, \" train_loss: \", losses / 794 , \" val_loss: \", val_losses / 94) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
