{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.utils as utills\n",
    "import numpy as np\n",
    "import torchsummary\n",
    "import torch.nn.functional as F\n",
    "from torchgan.layers import VirtualBatchNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "        self.filters = [1, 16, 32, 32, 64, 64, 128, 128, 256, 256, 512, 1024]\n",
    "        \n",
    "        for i in range(10):\n",
    "            self.layers.append(nn.Sequential(\n",
    "                nn.Conv1d(\n",
    "                    in_channels=self.filters[i] * 2, \n",
    "                    out_channels=self.filters[i+1] * 2,\n",
    "                    kernel_size = 32,\n",
    "                    stride=2,\n",
    "                    padding=15),\n",
    "                VirtualBatchNorm(self.filters[i+1] * 2),\n",
    "                nn.LeakyReLU(0.3)\n",
    "                 )\n",
    "             )\n",
    "                              \n",
    "        self.flatten = nn.Sequential(\n",
    "            nn.Conv1d(1024, 1, kernel_size=1, stride=1),\n",
    "            nn.LeakyReLU(0.3),\n",
    "            nn.Linear(16, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "                              \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        x = self.flatten(x)\n",
    "        return x\n",
    "        \n",
    "class NoiseCanceler(nn.Module):\n",
    "    def __init__(self, skip_z):\n",
    "        super(NoiseCanceler, self).__init__()\n",
    "            \n",
    "        self.enc_layers = nn.ModuleList()\n",
    "        self.dec_layers = nn.ModuleList()\n",
    "        self.filters = [1, 16, 32, 32, 64, 64, 128, 128, 256, 256, 512, 1024]\n",
    "        self.skip_z = skip_z\n",
    "        \n",
    "        self.prelu = nn.PReLU()\n",
    "        \n",
    "        # For Encoder [Batch x feature map x length]\n",
    "        for i in range(11):\n",
    "            self.enc_layers.append(nn.Conv1d(\n",
    "                    in_channels=self.filters[i], \n",
    "                    out_channels=self.filters[i+1],\n",
    "                    kernel_size = 32,\n",
    "                    stride=2,\n",
    "                    padding=15)\n",
    "               )\n",
    "               # output: [Batch x 1024 x 8]\n",
    "       \n",
    "        # For Decoder\n",
    "        # Gaussian random variable z, Whether or not to use.\n",
    "        for i in range(11, 0, -1):\n",
    "            if i == 11 and skip_z == True:\n",
    "                 self.dec_layers.append(nn.ConvTranspose1d(\n",
    "                        in_channels=self.filters[i], \n",
    "                        out_channels=self.filters[i-1],\n",
    "                        kernel_size = 32,\n",
    "                        stride=2,\n",
    "                        padding=15)\n",
    "                    )\n",
    "                  # output: [Batch x 1 x 16384]\n",
    "            else:\n",
    "                self.dec_layers.append(nn.ConvTranspose1d(\n",
    "                        in_channels=self.filters[i] * 2, \n",
    "                        out_channels=self.filters[i-1],\n",
    "                        kernel_size = 32,\n",
    "                        stride=2,\n",
    "                        padding=15)\n",
    "                    )\n",
    "                   # output: [Batch x 1 x 16384]  \n",
    "        self.dec_tanh = nn.Tanh()\n",
    "            \n",
    "    def forward(self, x, z):\n",
    "        values = []\n",
    "       \n",
    "        # Encoding\n",
    "        for enc in self.enc_layers:\n",
    "            x = self.prelu(enc(x))\n",
    "            values.append(x)\n",
    "        \n",
    "        # Enc out : Batch x 1024 x 8\n",
    "        values.reverse()\n",
    "        x = torch.cat((x, z), dim=1)\n",
    "            \n",
    "        # Decoding\n",
    "        for idx, dec in enumerate(self.dec_layers):\n",
    "            x = dec(x)\n",
    "            if idx < 10:\n",
    "                x = torch.cat((x, values[idx + 1]), dim=1)          \n",
    "                        \n",
    "        x = self.dec_tanh(x)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        values = []\n",
    "       \n",
    "        # Encoding\n",
    "        for enc in self.enc_layers:\n",
    "            x = self.prelu(enc(x))\n",
    "            values.append(x)\n",
    "        \n",
    "        # Enc out : Batch x 1024 x 8\n",
    "        values.reverse()\n",
    "        \n",
    "        # Decoding\n",
    "        for idx, dec in enumerate(self.dec_layers):\n",
    "            x = self.prelu(dec(x))\n",
    "            if idx < 10:\n",
    "                x = torch.cat((x, values[idx + 1]), dim=1)          \n",
    "                        \n",
    "        x = self.dec_tanh(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "NC = NoiseCanceler(True)\n",
    "D = Discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1             [-1, 16, 8192]             528\n",
      "             PReLU-2             [-1, 16, 8192]               1\n",
      "            Conv1d-3             [-1, 32, 4096]          16,416\n",
      "             PReLU-4             [-1, 32, 4096]               1\n",
      "            Conv1d-5             [-1, 32, 2048]          32,800\n",
      "             PReLU-6             [-1, 32, 2048]               1\n",
      "            Conv1d-7             [-1, 64, 1024]          65,600\n",
      "             PReLU-8             [-1, 64, 1024]               1\n",
      "            Conv1d-9              [-1, 64, 512]         131,136\n",
      "            PReLU-10              [-1, 64, 512]               1\n",
      "           Conv1d-11             [-1, 128, 256]         262,272\n",
      "            PReLU-12             [-1, 128, 256]               1\n",
      "           Conv1d-13             [-1, 128, 128]         524,416\n",
      "            PReLU-14             [-1, 128, 128]               1\n",
      "           Conv1d-15              [-1, 256, 64]       1,048,832\n",
      "            PReLU-16              [-1, 256, 64]               1\n",
      "           Conv1d-17              [-1, 256, 32]       2,097,408\n",
      "            PReLU-18              [-1, 256, 32]               1\n",
      "           Conv1d-19              [-1, 512, 16]       4,194,816\n",
      "            PReLU-20              [-1, 512, 16]               1\n",
      "           Conv1d-21              [-1, 1024, 8]      16,778,240\n",
      "            PReLU-22              [-1, 1024, 8]               1\n",
      "  ConvTranspose1d-23              [-1, 512, 16]      16,777,728\n",
      "            PReLU-24              [-1, 512, 16]               1\n",
      "  ConvTranspose1d-25              [-1, 256, 32]       8,388,864\n",
      "            PReLU-26              [-1, 256, 32]               1\n",
      "  ConvTranspose1d-27              [-1, 256, 64]       4,194,560\n",
      "            PReLU-28              [-1, 256, 64]               1\n",
      "  ConvTranspose1d-29             [-1, 128, 128]       2,097,280\n",
      "            PReLU-30             [-1, 128, 128]               1\n",
      "  ConvTranspose1d-31             [-1, 128, 256]       1,048,704\n",
      "            PReLU-32             [-1, 128, 256]               1\n",
      "  ConvTranspose1d-33              [-1, 64, 512]         524,352\n",
      "            PReLU-34              [-1, 64, 512]               1\n",
      "  ConvTranspose1d-35             [-1, 64, 1024]         262,208\n",
      "            PReLU-36             [-1, 64, 1024]               1\n",
      "  ConvTranspose1d-37             [-1, 32, 2048]         131,104\n",
      "            PReLU-38             [-1, 32, 2048]               1\n",
      "  ConvTranspose1d-39             [-1, 32, 4096]          65,568\n",
      "            PReLU-40             [-1, 32, 4096]               1\n",
      "  ConvTranspose1d-41             [-1, 16, 8192]          32,784\n",
      "            PReLU-42             [-1, 16, 8192]               1\n",
      "  ConvTranspose1d-43             [-1, 1, 16384]           1,025\n",
      "            PReLU-44             [-1, 1, 16384]               1\n",
      "             Tanh-45             [-1, 1, 16384]               0\n",
      "================================================================\n",
      "Total params: 58,676,663\n",
      "Trainable params: 58,676,663\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.06\n",
      "Forward/backward pass size (MB): 16.00\n",
      "Params size (MB): 223.83\n",
      "Estimated Total Size (MB): 239.90\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torchsummary.summary(NC, (1, 16384) , device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1             [-1, 32, 8192]           2,080\n",
      "  VirtualBatchNorm-2             [-1, 32, 8192]              32\n",
      "         LeakyReLU-3             [-1, 32, 8192]               0\n",
      "            Conv1d-4             [-1, 64, 4096]          65,600\n",
      "  VirtualBatchNorm-5             [-1, 64, 4096]              64\n",
      "         LeakyReLU-6             [-1, 64, 4096]               0\n",
      "            Conv1d-7             [-1, 64, 2048]         131,136\n",
      "  VirtualBatchNorm-8             [-1, 64, 2048]              64\n",
      "         LeakyReLU-9             [-1, 64, 2048]               0\n",
      "           Conv1d-10            [-1, 128, 1024]         262,272\n",
      " VirtualBatchNorm-11            [-1, 128, 1024]             128\n",
      "        LeakyReLU-12            [-1, 128, 1024]               0\n",
      "           Conv1d-13             [-1, 128, 512]         524,416\n",
      " VirtualBatchNorm-14             [-1, 128, 512]             128\n",
      "        LeakyReLU-15             [-1, 128, 512]               0\n",
      "           Conv1d-16             [-1, 256, 256]       1,048,832\n",
      " VirtualBatchNorm-17             [-1, 256, 256]             256\n",
      "        LeakyReLU-18             [-1, 256, 256]               0\n",
      "           Conv1d-19             [-1, 256, 128]       2,097,408\n",
      " VirtualBatchNorm-20             [-1, 256, 128]             256\n",
      "        LeakyReLU-21             [-1, 256, 128]               0\n",
      "           Conv1d-22              [-1, 512, 64]       4,194,816\n",
      " VirtualBatchNorm-23              [-1, 512, 64]             512\n",
      "        LeakyReLU-24              [-1, 512, 64]               0\n",
      "           Conv1d-25              [-1, 512, 32]       8,389,120\n",
      " VirtualBatchNorm-26              [-1, 512, 32]             512\n",
      "        LeakyReLU-27              [-1, 512, 32]               0\n",
      "           Conv1d-28             [-1, 1024, 16]      16,778,240\n",
      " VirtualBatchNorm-29             [-1, 1024, 16]           1,024\n",
      "        LeakyReLU-30             [-1, 1024, 16]               0\n",
      "           Conv1d-31                [-1, 1, 16]           1,025\n",
      "        LeakyReLU-32                [-1, 1, 16]               0\n",
      "           Linear-33                 [-1, 1, 1]              17\n",
      "          Sigmoid-34                 [-1, 1, 1]               0\n",
      "================================================================\n",
      "Total params: 33,497,938\n",
      "Trainable params: 33,494,962\n",
      "Non-trainable params: 2,976\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.12\n",
      "Forward/backward pass size (MB): 23.25\n",
      "Params size (MB): 127.78\n",
      "Estimated Total Size (MB): 151.16\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torchsummary.summary(D, (2, 16384) , device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
